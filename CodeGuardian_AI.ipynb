{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A5amzryrglzZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ast\n",
        "from textwrap import indent\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "myiqV5gBgqN4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FUNCTION_LABELS = [\n",
        "    \"data_processing\",\n",
        "    \"api_endpoint\",\n",
        "    \"utility\",\n",
        "    \"ml_model\",\n",
        "    \"database\",\n",
        "]\n",
        "\n",
        "def build_function_type_training_data():\n",
        "    examples = [\n",
        "        # Data processing\n",
        "        (\"\"\"\n",
        "def clean_dataframe(df):\n",
        "    df = df.dropna()\n",
        "    df = df.rename(columns=str.lower)\n",
        "    return df\n",
        "\"\"\", \"data_processing\"),\n",
        "        (\"\"\"\n",
        "def normalize_data(data):\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    return (data - mean) / std\n",
        "\"\"\", \"data_processing\"),\n",
        "\n",
        "        # API endpoints\n",
        "        (\"\"\"\n",
        "@app.route('/users', methods=['GET'])\n",
        "def get_users():\n",
        "    users = User.query.all()\n",
        "    return jsonify([u.to_dict() for u in users])\n",
        "\"\"\", \"api_endpoint\"),\n",
        "        (\"\"\"\n",
        "@router.post('/login')\n",
        "def login():\n",
        "    payload = request.json\n",
        "    token = auth_service.login(payload['email'], payload['password'])\n",
        "    return JSONResponse({'token': token})\n",
        "\"\"\", \"api_endpoint\"),\n",
        "\n",
        "        # Utility\n",
        "        (\"\"\"\n",
        "def slugify(text):\n",
        "    return text.lower().replace(\" \", \"-\")\n",
        "\"\"\", \"utility\"),\n",
        "        (\"\"\"\n",
        "def chunk_list(lst, size):\n",
        "    for i in range(0, len(lst), size):\n",
        "        yield lst[i:i+size]\n",
        "\"\"\", \"utility\"),\n",
        "\n",
        "        # ML model related\n",
        "        (\"\"\"\n",
        "def train_model(X_train, y_train):\n",
        "    model = RandomForestClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\"\"\", \"ml_model\"),\n",
        "        (\"\"\"\n",
        "def predict_proba(model, X):\n",
        "    return model.predict_proba(X)\n",
        "\"\"\", \"ml_model\"),\n",
        "\n",
        "        # Database\n",
        "        (\"\"\"\n",
        "def get_user_by_id(conn, user_id):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n",
        "    return cursor.fetchone()\n",
        "\"\"\", \"database\"),\n",
        "        (\"\"\"\n",
        "def save_order(session, order):\n",
        "    session.add(order)\n",
        "    session.commit()\n",
        "\"\"\", \"database\"),\n",
        "    ]\n",
        "\n",
        "    texts, labels = zip(*examples)\n",
        "    return list(texts), list(labels)\n",
        "\n",
        "def train_function_type_classifier():\n",
        "    texts, labels = build_function_type_training_data()\n",
        "\n",
        "    # test_size=0.5 so each of 5 classes gets at least 1 sample in train & val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        texts, labels, test_size=0.5, random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    clf = Pipeline([\n",
        "        (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2), max_features=5000)),\n",
        "        (\"svm\", LinearSVC())\n",
        "    ])\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"=== Function Type Classifier Validation ===\")\n",
        "    y_pred = clf.predict(X_val)\n",
        "    print(classification_report(y_val, y_pred))\n",
        "\n",
        "    return clf\n",
        "\n",
        "function_type_classifier = train_function_type_classifier()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh-i-sb3g-AT",
        "outputId": "56100762-128a-431b-ca4d-30121e691079"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Function Type Classifier Validation ===\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   api_endpoint       0.00      0.00      0.00         1\n",
            "data_processing       0.00      0.00      0.00         1\n",
            "       database       0.00      0.00      0.00         1\n",
            "       ml_model       0.33      1.00      0.50         1\n",
            "        utility       0.00      0.00      0.00         1\n",
            "\n",
            "       accuracy                           0.20         5\n",
            "      macro avg       0.07      0.20      0.10         5\n",
            "   weighted avg       0.07      0.20      0.10         5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "READABILITY_LABELS = [\"low\", \"medium\", \"high\"]\n",
        "\n",
        "def build_readability_training_data():\n",
        "    \"\"\"\n",
        "    Synthetic examples â€“ you can extend with your own.\n",
        "    \"\"\"\n",
        "    examples = [\n",
        "        # Low readability: no spacing, weird names, nested, long lines\n",
        "        (\"\"\"\n",
        "def f(a,b,c,d,e,f,g,h,i,j):print(a,b,c,d,e,f,g,h,i,j)\n",
        "\"\"\", \"low\"),\n",
        "        (\"\"\"\n",
        "def calc(x,y):\n",
        "    if x>0:\n",
        "        if y>0:\n",
        "            if x>y:\n",
        "                return x-y\n",
        "            else:\n",
        "                return y-x\n",
        "    else:\n",
        "        return x+y\n",
        "\"\"\", \"low\"),\n",
        "        (\"\"\"\n",
        "def do(a,b,c,d,e,f):\n",
        "    for i in range(len(a)):\n",
        "        for j in range(len(b)):\n",
        "            for k in range(len(c)):\n",
        "                for l in range(len(d)):\n",
        "                    print(i,j,k,l)\n",
        "\"\"\", \"low\"),\n",
        "\n",
        "        # Medium readability: okay but could be better\n",
        "        (\"\"\"\n",
        "def sum_list(values):\n",
        "    total = 0\n",
        "    for v in values:\n",
        "        total += v\n",
        "    return total\n",
        "\"\"\", \"medium\"),\n",
        "        (\"\"\"\n",
        "def filter_positive(nums):\n",
        "    result = []\n",
        "    for n in nums:\n",
        "        if n > 0:\n",
        "            result.append(n)\n",
        "    return result\n",
        "\"\"\", \"medium\"),\n",
        "        (\"\"\"\n",
        "def is_valid_email(email):\n",
        "    if \"@\" in email and \".\" in email:\n",
        "        return True\n",
        "    return False\n",
        "\"\"\", \"medium\"),\n",
        "\n",
        "        # High readability: docstrings, clear names, simple logic\n",
        "        (\"\"\"\n",
        "def compute_mean(values):\n",
        "    \\\"\\\"\\\"Return the arithmetic mean of a list of numbers.\\\"\\\"\\\"\n",
        "    if not values:\n",
        "        return 0.0\n",
        "    return sum(values) / len(values)\n",
        "\"\"\", \"high\"),\n",
        "        (\"\"\"\n",
        "def format_full_name(first_name, last_name):\n",
        "    \\\"\\\"\\\"Format a full name in 'Last, First' style.\\\"\\\"\\\"\n",
        "    first = first_name.strip().title()\n",
        "    last = last_name.strip().title()\n",
        "    return f\"{last}, {first}\"\n",
        "\"\"\", \"high\"),\n",
        "        (\"\"\"\n",
        "def chunk(iterable, size):\n",
        "    \\\"\\\"\\\"Yield fixed-size chunks from an iterable.\\\"\\\"\\\"\n",
        "    if size <= 0:\n",
        "        raise ValueError(\"size must be positive\")\n",
        "    for i in range(0, len(iterable), size):\n",
        "        yield iterable[i:i+size]\n",
        "\"\"\", \"high\"),\n",
        "    ]\n",
        "\n",
        "    texts, labels = zip(*examples)\n",
        "    return list(texts), list(labels)\n",
        "\n",
        "def train_readability_classifier():\n",
        "    texts, labels = build_readability_training_data()\n",
        "\n",
        "    # Small dataset â†’ simple split, no stratify to avoid edge errors\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        texts, labels, test_size=0.33, random_state=42\n",
        "    )\n",
        "\n",
        "    clf = Pipeline([\n",
        "        (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2), max_features=5000)),\n",
        "        (\"svm\", LinearSVC())\n",
        "    ])\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"=== Readability Classifier Validation ===\")\n",
        "    y_pred = clf.predict(X_val)\n",
        "    print(classification_report(y_val, y_pred))\n",
        "\n",
        "    return clf\n",
        "\n",
        "readability_classifier = train_readability_classifier()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz6yik5ghKoH",
        "outputId": "64e3ea0d-36fe-422e-d0f4-40c4e1a45401"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Readability Classifier Validation ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        high       0.00      0.00      0.00         1\n",
            "         low       0.00      0.00      0.00         1\n",
            "      medium       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.33      0.22         3\n",
            "weighted avg       0.17      0.33      0.22         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLEXITY_NODES = (\n",
        "    ast.If, ast.For, ast.While, ast.Try, ast.With,\n",
        "    ast.BoolOp, ast.IfExp, ast.comprehension\n",
        ")\n",
        "\n",
        "def compute_cyclomatic_complexity(node):\n",
        "    \"\"\"\n",
        "    Very simple cyclomatic complexity:\n",
        "    complexity = 1 + number of decision points.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    for child in ast.walk(node):\n",
        "        if isinstance(child, COMPLEXITY_NODES):\n",
        "            count += 1\n",
        "    return 1 + count\n",
        "\n",
        "def compute_max_depth(node, level=0):\n",
        "    \"\"\"\n",
        "    Approximate nesting depth of blocks.\n",
        "    \"\"\"\n",
        "    if not isinstance(node, ast.AST):\n",
        "        return level\n",
        "    max_child = level\n",
        "    for child in ast.iter_child_nodes(node):\n",
        "        child_depth = compute_max_depth(child, level + 1)\n",
        "        if child_depth > max_child:\n",
        "            max_child = child_depth\n",
        "    return max_child\n",
        "\n",
        "def analyze_ast_metrics(func_node, source_lines):\n",
        "    start = func_node.lineno - 1\n",
        "    end = getattr(func_node, \"end_lineno\", func_node.lineno)\n",
        "    num_lines = end - start\n",
        "\n",
        "    num_params = len(func_node.args.args)\n",
        "\n",
        "    complexity = compute_cyclomatic_complexity(func_node)\n",
        "    max_depth = compute_max_depth(func_node)\n",
        "\n",
        "    num_calls = 0\n",
        "    uses_eval_exec = False\n",
        "    uses_print_input = False\n",
        "    sql_like_strings = False\n",
        "\n",
        "    for n in ast.walk(func_node):\n",
        "        if isinstance(n, ast.Call):\n",
        "            num_calls += 1\n",
        "            if isinstance(n.func, ast.Name) and n.func.id in (\"eval\", \"exec\"):\n",
        "                uses_eval_exec = True\n",
        "            if isinstance(n.func, ast.Name) and n.func.id in (\"print\", \"input\"):\n",
        "                uses_print_input = True\n",
        "        if isinstance(n, ast.Constant) and isinstance(n.value, str):\n",
        "            text = n.value.upper()\n",
        "            if any(kw in text for kw in (\"SELECT \", \"INSERT \", \"UPDATE \", \"DELETE \")):\n",
        "                sql_like_strings = True\n",
        "\n",
        "    return {\n",
        "        \"num_lines\": num_lines,\n",
        "        \"num_params\": num_params,\n",
        "        \"complexity\": complexity,\n",
        "        \"max_depth\": max_depth,\n",
        "        \"num_calls\": num_calls,\n",
        "        \"uses_eval_exec\": uses_eval_exec,\n",
        "        \"uses_print_input\": uses_print_input,\n",
        "        \"sql_like_strings\": sql_like_strings,\n",
        "    }\n",
        "\n",
        "def detect_code_smells(ast_metrics, func_source):\n",
        "    smells = []\n",
        "\n",
        "    if ast_metrics[\"num_lines\"] > 50:\n",
        "        smells.append(\"Long Method (too many lines)\")\n",
        "\n",
        "    if ast_metrics[\"num_params\"] > 5:\n",
        "        smells.append(\"Long Parameter List (>5 parameters)\")\n",
        "\n",
        "    if ast_metrics[\"max_depth\"] > 4:\n",
        "        smells.append(\"Deeply Nested Logic (max depth > 4)\")\n",
        "\n",
        "    if ast_metrics[\"uses_eval_exec\"]:\n",
        "        smells.append(\"Use of eval/exec (security risk)\")\n",
        "\n",
        "    if ast_metrics[\"uses_print_input\"]:\n",
        "        smells.append(\"Uses print/input (debug or CLI in core logic)\")\n",
        "\n",
        "    if ast_metrics[\"sql_like_strings\"] and \"+\" in func_source:\n",
        "        smells.append(\"Possible SQL string concatenation (injection risk)\")\n",
        "\n",
        "    if \"password\" in func_source.lower() and (\"=\" in func_source):\n",
        "        smells.append(\"Possible hard-coded password/secret\")\n",
        "\n",
        "    return smells\n"
      ],
      "metadata": {
        "id": "vJpFLwQshToQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_functions_from_file(file_path):\n",
        "    \"\"\"\n",
        "    Parse a Python file and extract all top-level and class methods.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        source = f.read()\n",
        "\n",
        "    tree = ast.parse(source)\n",
        "    lines = source.splitlines()\n",
        "\n",
        "    functions = []\n",
        "\n",
        "    class FunctionVisitor(ast.NodeVisitor):\n",
        "        def __init__(self, outer_class=None):\n",
        "            self.outer_class = outer_class\n",
        "            super().__init__()\n",
        "\n",
        "        def visit_ClassDef(self, node):\n",
        "            visitor = FunctionVisitor(outer_class=node.name)\n",
        "            visitor.visit_nodes(node.body)\n",
        "\n",
        "        def visit_FunctionDef(self, node):\n",
        "            start = node.lineno - 1\n",
        "            end = getattr(node, \"end_lineno\", node.lineno)\n",
        "            func_source = \"\\n\".join(lines[start:end])\n",
        "\n",
        "            arg_names = [arg.arg for arg in node.args.args]\n",
        "            qualname = node.name\n",
        "            if self.outer_class:\n",
        "                qualname = f\"{self.outer_class}.{node.name}\"\n",
        "\n",
        "            metrics = analyze_ast_metrics(node, lines)\n",
        "            smells = detect_code_smells(metrics, func_source)\n",
        "\n",
        "            functions.append({\n",
        "                \"name\": node.name,\n",
        "                \"qualname\": qualname,\n",
        "                \"start_line\": start + 1,\n",
        "                \"end_line\": end,\n",
        "                \"source\": func_source,\n",
        "                \"args\": arg_names,\n",
        "                \"metrics\": metrics,\n",
        "                \"smells\": smells,\n",
        "            })\n",
        "\n",
        "        def visit_nodes(self, nodes):\n",
        "            for n in nodes:\n",
        "                self.visit(n)\n",
        "\n",
        "    visitor = FunctionVisitor()\n",
        "    visitor.visit_nodes(tree.body)\n",
        "\n",
        "    return functions\n"
      ],
      "metadata": {
        "id": "TeQDUgvYhTia"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "READABILITY_NUMERIC = {\n",
        "    \"low\": 3.0,\n",
        "    \"medium\": 6.0,\n",
        "    \"high\": 9.0,\n",
        "}\n",
        "\n",
        "def classify_function_type(func_source, model):\n",
        "    return model.predict([func_source])[0]\n",
        "\n",
        "def classify_readability(func_source, model):\n",
        "    label = model.predict([func_source])[0]\n",
        "    score = READABILITY_NUMERIC.get(label, 5.0)\n",
        "    return label, score\n",
        "\n",
        "def generate_function_summary(func_meta, func_type, read_label):\n",
        "    name = func_meta[\"qualname\"]\n",
        "    args = func_meta[\"args\"]\n",
        "\n",
        "    args_str = \", \".join(args) if args else \"no arguments\"\n",
        "\n",
        "    type_descriptions = {\n",
        "        \"data_processing\": \"Performs data cleaning or transformation.\",\n",
        "        \"api_endpoint\": \"Exposes an API endpoint or HTTP route.\",\n",
        "        \"utility\": \"Provides a general-purpose helper/utility.\",\n",
        "        \"ml_model\": \"Trains or uses a machine-learning model.\",\n",
        "        \"database\": \"Interacts with a database or persistent storage.\",\n",
        "    }\n",
        "\n",
        "    type_desc = type_descriptions.get(func_type, \"General-purpose function.\")\n",
        "\n",
        "    return f\"{name}({args_str}) â€” {type_desc} Readability is classified as **{read_label}**.\"\n",
        "\n",
        "def generate_auto_refactor_suggestion(func_meta):\n",
        "    \"\"\"\n",
        "    Heuristic-based refactor suggestion.\n",
        "    This is NOT changing the original file, just giving a suggested version.\n",
        "    Focus: readability + performance + security hints.\n",
        "    \"\"\"\n",
        "    src = func_meta[\"source\"]\n",
        "    lines = src.splitlines()\n",
        "    if not lines:\n",
        "        return src  # nothing to do\n",
        "\n",
        "    # Ensure docstring\n",
        "    ref_lines = lines.copy()\n",
        "    def_line = ref_lines[0]\n",
        "    indent_spaces = \" \" * (len(def_line) - len(def_line.lstrip(\" \")))\n",
        "\n",
        "    has_docstring = False\n",
        "    if len(ref_lines) > 1:\n",
        "        stripped = ref_lines[1].strip()\n",
        "        if (stripped.startswith('\"\"\"') and stripped.endswith('\"\"\"')) or \\\n",
        "           (stripped.startswith(\"'''\") and stripped.endswith(\"'''\")):\n",
        "            has_docstring = True\n",
        "\n",
        "    if not has_docstring:\n",
        "        docstring = indent_spaces + '    \"\"\"TODO: Add meaningful docstring.\"\"\"'\n",
        "        if len(ref_lines) == 1:\n",
        "            ref_lines.append(docstring)\n",
        "        else:\n",
        "            ref_lines.insert(1, docstring)\n",
        "\n",
        "    # Append security/performance comments at the end if smells detected\n",
        "    metrics = func_meta[\"metrics\"]\n",
        "    smells = func_meta[\"smells\"]\n",
        "\n",
        "    comment_block = []\n",
        "    comment_block.append(indent_spaces + \"# Auto-refactor hints:\")\n",
        "    if metrics[\"num_lines\"] > 50:\n",
        "        comment_block.append(indent_spaces + \"# - Consider splitting into smaller functions.\")\n",
        "    if metrics[\"max_depth\"] > 4:\n",
        "        comment_block.append(indent_spaces + \"# - Reduce nesting with early returns or helpers.\")\n",
        "    if metrics[\"uses_eval_exec\"]:\n",
        "        comment_block.append(indent_spaces + \"# - Replace eval/exec with safe alternatives.\")\n",
        "    if metrics[\"sql_like_strings\"]:\n",
        "        comment_block.append(indent_spaces + \"# - Use parameterized queries instead of string concatenation.\")\n",
        "    if metrics[\"num_params\"] > 5:\n",
        "        comment_block.append(indent_spaces + \"# - Group related parameters into objects or dataclasses.\")\n",
        "\n",
        "    if len(comment_block) > 1:\n",
        "        ref_lines.append(\"\")  # blank line\n",
        "        ref_lines.extend(comment_block)\n",
        "\n",
        "    return \"\\n\".join(ref_lines)\n"
      ],
      "metadata": {
        "id": "VR0ryF9zhTbX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_markdown_documentation(file_path, functions,\n",
        "                                    type_model, read_model):\n",
        "    md_lines = []\n",
        "    md_lines.append(f\"# Auto-Generated Code Intelligence Report\\n\")\n",
        "    md_lines.append(f\"**Source file:** `{os.path.basename(file_path)}`\\n\")\n",
        "    md_lines.append(\"---\\n\")\n",
        "\n",
        "    for func in functions:\n",
        "        func_type = classify_function_type(func[\"source\"], type_model)\n",
        "        read_label, read_score = classify_readability(func[\"source\"], read_model)\n",
        "        summary = generate_function_summary(func, func_type, read_label)\n",
        "        metrics = func[\"metrics\"]\n",
        "        smells = func[\"smells\"]\n",
        "        refactored = generate_auto_refactor_suggestion(func)\n",
        "\n",
        "        md_lines.append(f\"## `{func['qualname']}`\")\n",
        "        md_lines.append(f\"- **Lines:** {func['start_line']}â€“{func['end_line']}\")\n",
        "        md_lines.append(f\"- **Type (ML classified):** `{func_type}`\")\n",
        "        md_lines.append(f\"- **Readability:** `{read_label}` (score â‰ˆ {read_score:.1f}/10)\")\n",
        "        md_lines.append(f\"- **Cyclomatic Complexity:** `{metrics['complexity']}`\")\n",
        "        md_lines.append(f\"- **Max Nesting Depth:** `{metrics['max_depth']}`\")\n",
        "        md_lines.append(f\"- **Parameters:** `{metrics['num_params']}`\")\n",
        "        md_lines.append(f\"- **Function Calls:** `{metrics['num_calls']}`\")\n",
        "\n",
        "        if smells:\n",
        "            md_lines.append(f\"- **Detected Code Smells:**\")\n",
        "            for s in smells:\n",
        "                md_lines.append(f\"  - {s}\")\n",
        "        else:\n",
        "            md_lines.append(f\"- **Detected Code Smells:** None ðŸŽ‰\")\n",
        "\n",
        "        md_lines.append(f\"- **Summary:** {summary}\\n\")\n",
        "\n",
        "        # Original source\n",
        "        md_lines.append(\"<details><summary>Original Source Code</summary>\\n\")\n",
        "        md_lines.append(\"\")\n",
        "        md_lines.append(\"```python\")\n",
        "        md_lines.append(func[\"source\"])\n",
        "        md_lines.append(\"```\")\n",
        "        md_lines.append(\"\\n</details>\\n\")\n",
        "\n",
        "        # Refactored suggestion\n",
        "        md_lines.append(\"<details><summary>Auto-Refactor Suggestion</summary>\\n\")\n",
        "        md_lines.append(\"\")\n",
        "        md_lines.append(\"```python\")\n",
        "        md_lines.append(refactored)\n",
        "        md_lines.append(\"```\")\n",
        "        md_lines.append(\"\\n</details>\\n\")\n",
        "\n",
        "        md_lines.append(\"---\\n\")\n",
        "\n",
        "    md_content = \"\\n\".join(md_lines)\n",
        "\n",
        "    out_path = os.path.join(os.path.dirname(file_path), \"DOCUMENTATION.md\")\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(md_content)\n",
        "\n",
        "    return out_path\n"
      ],
      "metadata": {
        "id": "g4TrD7qThTRf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_code_file(file_path,\n",
        "                      type_model=None,\n",
        "                      read_model=None):\n",
        "    if type_model is None or read_model is None:\n",
        "        raise ValueError(\"Models cannot be None. Pass both type_model and read_model.\")\n",
        "\n",
        "    print(f\"Analyzing: {file_path}\")\n",
        "\n",
        "    functions = extract_functions_from_file(file_path)\n",
        "    if not functions:\n",
        "        print(\"No functions found!\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(functions)} functions/methods.\\n\")\n",
        "\n",
        "    for func in functions:\n",
        "        func_type = classify_function_type(func[\"source\"], type_model)\n",
        "        read_label, read_score = classify_readability(func[\"source\"], read_model)\n",
        "        metrics = func[\"metrics\"]\n",
        "        smells = func[\"smells\"]\n",
        "\n",
        "        print(f\"- {func['qualname']} (lines {func['start_line']}â€“{func['end_line']})\")\n",
        "        print(f\"  Type: {func_type}\")\n",
        "        print(f\"  Readability: {read_label} (â‰ˆ {read_score:.1f}/10)\")\n",
        "        print(f\"  Complexity: {metrics['complexity']}, Max depth: {metrics['max_depth']}\")\n",
        "        print(f\"  Params: {metrics['num_params']}, Calls: {metrics['num_calls']}\")\n",
        "        if smells:\n",
        "            print(\"  Smells:\")\n",
        "            for s in smells:\n",
        "                print(f\"    - {s}\")\n",
        "        else:\n",
        "            print(\"  Smells: None\")\n",
        "        print()\n",
        "\n",
        "    doc_path = generate_markdown_documentation(\n",
        "        file_path, functions, type_model, read_model\n",
        "    )\n",
        "    print(f\"\\nðŸ“„ Documentation generated at: {doc_path}\")\n"
      ],
      "metadata": {
        "id": "UFqvfwGbhS_O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_code_file(file_path,\n",
        "                      type_model=None,\n",
        "                      read_model=None):\n",
        "    if type_model is None or read_model is None:\n",
        "        raise ValueError(\"Models cannot be None. Pass both type_model and read_model.\")\n",
        "\n",
        "    print(f\"Analyzing: {file_path}\")\n",
        "\n",
        "    functions = extract_functions_from_file(file_path)\n",
        "    if not functions:\n",
        "        print(\"No functions found!\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(functions)} functions/methods.\\n\")\n",
        "\n",
        "    for func in functions:\n",
        "        func_type = classify_function_type(func[\"source\"], type_model)\n",
        "        read_label, read_score = classify_readability(func[\"source\"], read_model)\n",
        "        metrics = func[\"metrics\"]\n",
        "        smells = func[\"smells\"]\n",
        "\n",
        "        print(f\"- {func['qualname']} (lines {func['start_line']}â€“{func['end_line']})\")\n",
        "        print(f\"  Type: {func_type}\")\n",
        "        print(f\"  Readability: {read_label} (â‰ˆ {read_score:.1f}/10)\")\n",
        "        print(f\"  Complexity: {metrics['complexity']}, Max depth: {metrics['max_depth']}\")\n",
        "        print(f\"  Params: {metrics['num_params']}, Calls: {metrics['num_calls']}\")\n",
        "        if smells:\n",
        "            print(\"  Smells:\")\n",
        "            for s in smells:\n",
        "                print(f\"    - {s}\")\n",
        "        else:\n",
        "            print(\"  Smells: None\")\n",
        "        print()\n",
        "\n",
        "    doc_path = generate_markdown_documentation(\n",
        "        file_path, functions, type_model, read_model\n",
        "    )\n",
        "    print(f\"\\nðŸ“„ Documentation generated at: {doc_path}\")\n"
      ],
      "metadata": {
        "id": "z25vrRAyhpdm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_code = \"\"\"\n",
        "import numpy as np\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "def clean_dataframe(df):\n",
        "    df = df.dropna()\n",
        "    df = df.rename(columns=str.lower)\n",
        "    return df\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    payload = request.json\n",
        "    features = np.array(payload['features']).reshape(1, -1)\n",
        "    # dummy prediction\n",
        "    score = float(features.mean())\n",
        "    return jsonify({'score': score})\n",
        "\n",
        "class UserRepository:\n",
        "    def __init__(self, conn, debug=False, password='secret123'):\n",
        "        self.conn = conn\n",
        "        self.debug = debug\n",
        "        self.password = password\n",
        "\n",
        "    def get_user(self, user_id):\n",
        "        cursor = self.conn.cursor()\n",
        "        query = \"SELECT * FROM users WHERE id = \" + str(user_id)\n",
        "        cursor.execute(query)\n",
        "        return cursor.fetchone()\n",
        "\n",
        "def helper_format_user(user):\n",
        "    return {\n",
        "        'id': user[0],\n",
        "        'name': user[1],\n",
        "    }\n",
        "\n",
        "def ugly_function(a,b,c,d,e,f,g,h,i,j):\n",
        "    if a>b:\n",
        "        if b>c:\n",
        "            if c>d:\n",
        "                if d>e:\n",
        "                    if e>f:\n",
        "                        if f>g:\n",
        "                            print(a,b,c,d,e,f,g,h,i,j)\n",
        "\"\"\"\n",
        "\n",
        "test_file_path = \"/content/sample_app.py\"\n",
        "with open(test_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(sample_code)\n",
        "\n",
        "print(f\"Sample file written to: {test_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zx5wpkAhpUY",
        "outputId": "79ebe54c-d3cc-4612-8ec7-588b21de5db1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample file written to: /content/sample_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_code_file(\n",
        "    test_file_path,\n",
        "    type_model=function_type_classifier,\n",
        "    read_model=readability_classifier,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeYdJdTViX8v",
        "outputId": "a5d778c8-91df-4003-fb15-08f8932781f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing: /content/sample_app.py\n",
            "Found 6 functions/methods.\n",
            "\n",
            "- clean_dataframe (lines 7â€“10)\n",
            "  Type: data_processing\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 1, Max depth: 6\n",
            "  Params: 1, Calls: 2\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "\n",
            "- predict (lines 13â€“18)\n",
            "  Type: api_endpoint\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 1, Max depth: 7\n",
            "  Params: 0, Calls: 6\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "\n",
            "- UserRepository.__init__ (lines 21â€“24)\n",
            "  Type: api_endpoint\n",
            "  Readability: low (â‰ˆ 3.0/10)\n",
            "  Complexity: 1, Max depth: 4\n",
            "  Params: 4, Calls: 0\n",
            "  Smells:\n",
            "    - Possible hard-coded password/secret\n",
            "\n",
            "- UserRepository.get_user (lines 26â€“30)\n",
            "  Type: data_processing\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 1, Max depth: 6\n",
            "  Params: 2, Calls: 4\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "    - Possible SQL string concatenation (injection risk)\n",
            "\n",
            "- helper_format_user (lines 32â€“36)\n",
            "  Type: ml_model\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 1, Max depth: 5\n",
            "  Params: 1, Calls: 0\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "\n",
            "- ugly_function (lines 38â€“45)\n",
            "  Type: ml_model\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 7, Max depth: 10\n",
            "  Params: 10, Calls: 1\n",
            "  Smells:\n",
            "    - Long Parameter List (>5 parameters)\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "    - Uses print/input (debug or CLI in core logic)\n",
            "\n",
            "\n",
            "ðŸ“„ Documentation generated at: /content/DOCUMENTATION.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/test_ml_api.py\"  # or whichever you upload\n",
        "analyze_code_file(\n",
        "    file_path,\n",
        "    type_model=function_type_classifier,\n",
        "    read_model=readability_classifier,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWKKzK6AiexX",
        "outputId": "ef94eab4-0510-4c99-e997-a86c3660ff6a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing: /content/test_ml_api.py\n",
            "Found 5 functions/methods.\n",
            "\n",
            "- load_data (lines 8â€“12)\n",
            "  Type: api_endpoint\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 2, Max depth: 6\n",
            "  Params: 1, Calls: 4\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "\n",
            "- train_model (lines 14â€“18)\n",
            "  Type: ml_model\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 1, Max depth: 5\n",
            "  Params: 0, Calls: 3\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "\n",
            "- predict (lines 21â€“25)\n",
            "  Type: ml_model\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 1, Max depth: 8\n",
            "  Params: 0, Calls: 7\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "\n",
            "- bad_database_fetch (lines 27â€“32)\n",
            "  Type: ml_model\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 1, Max depth: 5\n",
            "  Params: 2, Calls: 3\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "    - Possible SQL string concatenation (injection risk)\n",
            "\n",
            "- helper (lines 34â€“35)\n",
            "  Type: utility\n",
            "  Readability: high (â‰ˆ 9.0/10)\n",
            "  Complexity: 2, Max depth: 5\n",
            "  Params: 1, Calls: 0\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "\n",
            "\n",
            "ðŸ“„ Documentation generated at: /content/DOCUMENTATION.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/test_ugly_utils.py\"  # or whichever you upload\n",
        "analyze_code_file(\n",
        "    file_path,\n",
        "    type_model=function_type_classifier,\n",
        "    read_model=readability_classifier,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "497HjfZijW7f",
        "outputId": "d80fec05-6d15-4ae3-d684-dac6da7d6bf9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing: /content/test_ugly_utils.py\n",
            "Found 3 functions/methods.\n",
            "\n",
            "- process (lines 1â€“12)\n",
            "  Type: ml_model\n",
            "  Readability: low (â‰ˆ 3.0/10)\n",
            "  Complexity: 8, Max depth: 12\n",
            "  Params: 10, Calls: 2\n",
            "  Smells:\n",
            "    - Long Parameter List (>5 parameters)\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "    - Uses print/input (debug or CLI in core logic)\n",
            "\n",
            "- format_data (lines 14â€“15)\n",
            "  Type: utility\n",
            "  Readability: low (â‰ˆ 3.0/10)\n",
            "  Complexity: 2, Max depth: 5\n",
            "  Params: 1, Calls: 1\n",
            "  Smells:\n",
            "    - Deeply Nested Logic (max depth > 4)\n",
            "\n",
            "- useless_function (lines 17â€“21)\n",
            "  Type: ml_model\n",
            "  Readability: low (â‰ˆ 3.0/10)\n",
            "  Complexity: 1, Max depth: 4\n",
            "  Params: 1, Calls: 3\n",
            "  Smells:\n",
            "    - Uses print/input (debug or CLI in core logic)\n",
            "\n",
            "\n",
            "ðŸ“„ Documentation generated at: /content/DOCUMENTATION.md\n"
          ]
        }
      ]
    }
  ]
}